The study adequately presents the practical differences between training, testing and validation processes, albeit with usage of unprofessional language like capitalized words and exclamation marks. 

It proposes algorithmic performance evaluation through trading simulations, initially focusing on a single oil share. Upon achieving satisfactory validation results, the model is tested. The validation process helps in model adjustment in case of high error rates, maybe necessitating a  re-initialization of the Hill Climbing method for Bayesian model learning. The paper categorically mentions that testing is advised only after attaining satisfactory validation performance, maintaining methodological integrity and preventing data leakage.